{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ferramentas para NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, lower, monotonically_increasing_id, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"encoding\", \"ISO-8859-1\").text(['data.txt', 'class.txt', 'newtest.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"value\", regexp_replace(lower(df[\"value\"]), \"[$&+,:;=?@#|'<>.-^*()%!]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.select('*').withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               value|         id|\n",
      "+--------------------+-----------+\n",
      "|classificacao reg...|          0|\n",
      "|aqui um arquivo d...| 8589934592|\n",
      "|    novão pra checar|17179869184|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegexTokenizer\n",
    "\n",
    "O RegexTokenizer permite uma tokenização mais avançada com base na correspondência de expressões regulares (regex). Por padrão, o parâmetro “pattern” (regex, padrão: \"\\ s +\") é usado como delimitadores para dividir o texto de entrada. Alternativamente, os usuários podem definir o parâmetro “gaps” para false, indicando que o “padrão” da regex denota “tokens”, em vez de dividir lacunas, e encontrar todas as ocorrências correspondentes como o resultado da tokenização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classificacao regressao modelos sao legais</td>\n",
       "      <td>0</td>\n",
       "      <td>[classificacao, regressao, modelos, sao, legais]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aqui um arquivo de texto</td>\n",
       "      <td>8589934592</td>\n",
       "      <td>[aqui, um, arquivo, de, texto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novão pra checar</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>[novão, pra, checar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        value           id  \\\n",
       "0  classificacao regressao modelos sao legais            0   \n",
       "1                    aqui um arquivo de texto   8589934592   \n",
       "2                            novão pra checar  17179869184   \n",
       "\n",
       "                                              words  \n",
       "0  [classificacao, regressao, modelos, sao, legais]  \n",
       "1                    [aqui, um, arquivo, de, texto]  \n",
       "2                              [novão, pra, checar]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"value\", outputCol=\"words\")\n",
    "\n",
    "#extrai o token de acordo com o que foi especificado - aqui foi especificado\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"value\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# pattern=\"\\\\w+\", gaps(False)\n",
    "\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "tokenized = tokenizer.transform(df)\n",
    "tokenized.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classificacao regressao modelos sao legais</td>\n",
       "      <td>[classificacao, regressao, modelos, sao, legais]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aqui um arquivo de texto</td>\n",
       "      <td>[aqui, um, arquivo, de, texto]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novão pra checar</td>\n",
       "      <td>[novão, pra, checar]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        value  \\\n",
       "0  classificacao regressao modelos sao legais   \n",
       "1                    aqui um arquivo de texto   \n",
       "2                            novão pra checar   \n",
       "\n",
       "                                              words  tokens  \n",
       "0  [classificacao, regressao, modelos, sao, legais]       5  \n",
       "1                    [aqui, um, arquivo, de, texto]       5  \n",
       "2                              [novão, pra, checar]       3  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.select(\"value\", \"words\")\\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\"))).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Removendo Stop Words\n",
    "\n",
    "Stop Words são palavras que devem ser excluídas da entrada, normalmente porque as palavras aparecem com frequência e não têm tanto significado.\n",
    "\n",
    "StopWordsRemover toma como entrada uma sequência de strings (por exemplo, a saída de um Tokenizer) e elimina todas as palavras de parada das seqüências de entrada. A lista de Stop Words é especificada pelo parâmetro stopWords. As Stop Words padrões para alguns idiomas são acessíveis chamando StopWordsRemover.loadDefaultStopWords(idioma), para o qual as opções disponíveis são “danish”, “dutch”, “english”, “finnish”, “french”, “german”, “hungarian”, “italian”, “norwegian”, “portuguese”, “russian”, “spanish”, “swedish” and “turkish”. Um parâmetro booleano caseSensitive indica se as correspondências devem diferenciar maiúsculas de minúsculas (falso por padrão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "language=\"portuguese\"\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=StopWordsRemover.loadDefaultStopWords(language))\n",
    "remover = remover.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classificacao regressao modelos sao legais</td>\n",
       "      <td>0</td>\n",
       "      <td>[classificacao, regressao, modelos, sao, legais]</td>\n",
       "      <td>[classificacao, regressao, modelos, sao, legais]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aqui um arquivo de texto</td>\n",
       "      <td>8589934592</td>\n",
       "      <td>[aqui, um, arquivo, de, texto]</td>\n",
       "      <td>[aqui, arquivo, texto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novão pra checar</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>[novão, pra, checar]</td>\n",
       "      <td>[novão, pra, checar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        value           id  \\\n",
       "0  classificacao regressao modelos sao legais            0   \n",
       "1                    aqui um arquivo de texto   8589934592   \n",
       "2                            novão pra checar  17179869184   \n",
       "\n",
       "                                              words  \\\n",
       "0  [classificacao, regressao, modelos, sao, legais]   \n",
       "1                    [aqui, um, arquivo, de, texto]   \n",
       "2                              [novão, pra, checar]   \n",
       "\n",
       "                                           filtered  \n",
       "0  [classificacao, regressao, modelos, sao, legais]  \n",
       "1                            [aqui, arquivo, texto]  \n",
       "2                              [novão, pra, checar]  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gramas\n",
    "\n",
    "NGram toma como entrada uma seqüência strings (por exemplo, a saída de um Tokenizer). O parâmetro n é usado para determinar o número de termos em cada n-grama. A saída consistirá de uma sequência de n-gramas, onde cada n-grama é representado por uma string delimitada por espaço de n palavras consecutivas. Se a sequência de entrada contiver menos de n cadeias, nenhuma saída será produzida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "|ngrams                                                               |\n",
      "+---------------------------------------------------------------------+\n",
      "|[classificacao regressao, regressao modelos, modelos sao, sao legais]|\n",
      "|[aqui arquivo, arquivo texto]                                        |\n",
      "|[novão pra, pra checar]                                              |\n",
      "+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "ngram = NGram(n=2, inputCol=\"filtered\", outputCol=\"ngrams\")\n",
    "ngramDataFrame = ngram.transform(remover)\n",
    "\n",
    "ngramDataFrame.select(\"ngrams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "# TF-IDF\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            sentence|\n",
      "+-----+--------------------+\n",
      "|  0.0|Ola ja ouvi falar...|\n",
      "|  1.0|Eu gostaria de us...|\n",
      "|  2.0|Classificacao,reg...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Ola ja ouvi falar de Spark\"),\n",
    "    (1.0, \"Eu gostaria de usar datascience em tudo\"),\n",
    "    (2.0, \"Classificacao,regressao,modelos,sao,legais\")\n",
    "], [\"label\", \"sentence\"])\n",
    "\n",
    "sentenceData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            sentence|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|Ola ja ouvi falar...|[ola, ja, ouvi, f...|\n",
      "|  1.0|Eu gostaria de us...|[eu, gostaria, de...|\n",
      "|  2.0|Classificacao,reg...|[classificacao,re...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "wordsData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "O CountVectorizer selecionará as melhores palavras com um tamanho igual ao valor especificado pelo parâmetro vocabSize, ordenadas pela frequência do termo em todo o corpus. Um parâmetro opcional minDF também afeta o processo de ajuste, especificando o número mínimo dos documentos em que um termo deve aparecer para ser incluído no vocabulário. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_vectorizer(data, inputName=\"words\"):\n",
    "    cv = CountVectorizer(inputCol=inputName, outputCol=\"features\")\n",
    "    #minDf o termo só aparece se estiver em mais documentos que o minimo.\n",
    "    model = cv.fit(df)\n",
    "    result = model.transform(df)\n",
    "    return result, model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classificacao regressao modelos sao legais</td>\n",
       "      <td>0</td>\n",
       "      <td>[classificacao, regressao, modelos, sao, legais]</td>\n",
       "      <td>[classificacao, regressao, modelos, sao, legais]</td>\n",
       "      <td>[classificacao regressao, regressao modelos, m...</td>\n",
       "      <td>(1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aqui um arquivo de texto</td>\n",
       "      <td>8589934592</td>\n",
       "      <td>[aqui, um, arquivo, de, texto]</td>\n",
       "      <td>[aqui, arquivo, texto]</td>\n",
       "      <td>[aqui arquivo, arquivo texto]</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novão pra checar</td>\n",
       "      <td>17179869184</td>\n",
       "      <td>[novão, pra, checar]</td>\n",
       "      <td>[novão, pra, checar]</td>\n",
       "      <td>[novão pra, pra checar]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        value           id  \\\n",
       "0  classificacao regressao modelos sao legais            0   \n",
       "1                    aqui um arquivo de texto   8589934592   \n",
       "2                            novão pra checar  17179869184   \n",
       "\n",
       "                                              words  \\\n",
       "0  [classificacao, regressao, modelos, sao, legais]   \n",
       "1                    [aqui, um, arquivo, de, texto]   \n",
       "2                              [novão, pra, checar]   \n",
       "\n",
       "                                           filtered  \\\n",
       "0  [classificacao, regressao, modelos, sao, legais]   \n",
       "1                            [aqui, arquivo, texto]   \n",
       "2                              [novão, pra, checar]   \n",
       "\n",
       "                                              ngrams  \\\n",
       "0  [classificacao regressao, regressao modelos, m...   \n",
       "1                      [aqui arquivo, arquivo texto]   \n",
       "2                            [novão pra, pra checar]   \n",
       "\n",
       "                                   features  \n",
       "0  (1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0)  \n",
       "1  (0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0)  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#cada linha é um \"bag of words\" com um ID.\n",
    "# df = spark.createDataFrame([\n",
    "#     (0, \"a b c j\".split(\" \")),\n",
    "#     (1, [\"a\", \"b\", \"b\", \"c\", \"a\", \"k\"])\n",
    "# ], [\"id\", \"words\"])\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"ngrams\", outputCol=\"features\")\n",
    "#minDf o termo só aparece se estiver em mais documentos que o minimo.\n",
    "model = cv.fit(ngramDataFrame)\n",
    "\n",
    "result = model.transform(ngramDataFrame)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classificacao regressao', 'regressao modelos', 'modelos sao', 'sao legais']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('ngrams').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('features').collect()[1][0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classificacao regressao',\n",
       " 'arquivo texto',\n",
       " 'sao legais',\n",
       " 'modelos sao',\n",
       " 'aqui arquivo',\n",
       " 'pra checar',\n",
       " 'novão pra',\n",
       " 'regressao modelos']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
